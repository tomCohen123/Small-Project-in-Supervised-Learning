#ideas:
# use late pruning on each tree if there is enough time

#look for best group v for late pruning with barrier and random

#give different weight to features some how



#find best train subgroup from train with random size and places
#change is majority val
#normalization of data
#best values for forest:
# N=9
# K=5
# P=0.3


"""data pre processing is prohibited"""
"""loss is not interesting"""

#choose a smaller learning group with parameter tuning to avoid overfiting with combined kfold
#normalization of paramerter
#use here majority threshold